<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>量子鸢尾花分类 | ZTCodeGarden</title><meta name="author" content="陈智涛"><meta name="copyright" content="陈智涛"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="项目说明作用处理数据1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991">
<meta property="og:type" content="article">
<meta property="og:title" content="量子鸢尾花分类">
<meta property="og:url" content="http://example.com/2024/11/30/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97%E9%A1%B9%E7%9B%AE/%E9%87%8F%E5%AD%90%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%88%86%E7%B1%BB/index.html">
<meta property="og:site_name" content="ZTCodeGarden">
<meta property="og:description" content="项目说明作用处理数据1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/01.jpg">
<meta property="article:published_time" content="2024-11-30T13:21:52.000Z">
<meta property="article:modified_time" content="2024-12-01T02:48:00.516Z">
<meta property="article:author" content="陈智涛">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/01.jpg"><link rel="shortcut icon" href="/img/02.jpg"><link rel="canonical" href="http://example.com/2024/11/30/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97%E9%A1%B9%E7%9B%AE/%E9%87%8F%E5%AD%90%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%88%86%E7%B1%BB/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":true,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '量子鸢尾花分类',
  isPost: true,
  isHome: false,
  isHighlightShrink: true,
  isToc: true,
  isShuoshuo: false
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image: url(/img/02.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/01.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">16</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">ZTCodeGarden</span></a><a class="nav-page-title" href="/"><span class="site-name">量子鸢尾花分类</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">量子鸢尾花分类</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-11-30T13:21:52.000Z" title="发表于 2024-11-30 21:21:52">2024-11-30</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-12-01T02:48:00.516Z" title="更新于 2024-12-01 10:48:00">2024-12-01</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="项目说明"><a href="#项目说明" class="headerlink" title="项目说明"></a>项目说明</h2><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><h2 id="处理数据"><a href="#处理数据" class="headerlink" title="处理数据"></a>处理数据</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line">3.999999999999999112e-01 7.500000000000000000e-01 1.999999999999999556e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">3.000000000000002665e-01 5.000000000000000000e-01 1.999999999999999556e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">2.000000000000001776e-01 6.000000000000000888e-01 1.500000000000000222e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">1.499999999999999112e-01 5.500000000000000444e-01 2.500000000000000000e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">3.500000000000000888e-01 8.000000000000000444e-01 1.999999999999999556e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">5.500000000000002665e-01 9.499999999999999556e-01 3.499999999999999778e-01 1.500000000000000222e-01 -1.000000000000000000e+00</span><br><span class="line">1.499999999999999112e-01 6.999999999999999556e-01 1.999999999999999556e-01 9.999999999999999167e-02 -1.000000000000000000e+00</span><br><span class="line">3.500000000000000888e-01 6.999999999999999556e-01 2.500000000000000000e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">5.000000000000026645e-02 4.499999999999999556e-01 1.999999999999999556e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">3.000000000000002665e-01 5.500000000000000444e-01 2.500000000000000000e-01 0.000000000000000000e+00 -1.000000000000000000e+00</span><br><span class="line">5.500000000000002665e-01 8.500000000000000888e-01 2.500000000000000000e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">2.500000000000000000e-01 6.999999999999999556e-01 3.000000000000000444e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">2.500000000000000000e-01 5.000000000000000000e-01 1.999999999999999556e-01 0.000000000000000000e+00 -1.000000000000000000e+00</span><br><span class="line">0.000000000000000000e+00 5.000000000000000000e-01 5.000000000000004441e-02 0.000000000000000000e+00 -1.000000000000000000e+00</span><br><span class="line">7.500000000000000000e-01 1.000000000000000000e+00 9.999999999999997780e-02 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">7.000000000000001776e-01 1.200000000000000178e+00 2.500000000000000000e-01 1.500000000000000222e-01 -1.000000000000000000e+00</span><br><span class="line">5.500000000000002665e-01 9.499999999999999556e-01 1.500000000000000222e-01 1.500000000000000222e-01 -1.000000000000000000e+00</span><br><span class="line">3.999999999999999112e-01 7.500000000000000000e-01 1.999999999999999556e-01 9.999999999999999167e-02 -1.000000000000000000e+00</span><br><span class="line">7.000000000000001776e-01 8.999999999999999112e-01 3.499999999999999778e-01 9.999999999999999167e-02 -1.000000000000000000e+00</span><br><span class="line">3.999999999999999112e-01 8.999999999999999112e-01 2.500000000000000000e-01 9.999999999999999167e-02 -1.000000000000000000e+00</span><br><span class="line">5.500000000000002665e-01 6.999999999999999556e-01 3.499999999999999778e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">3.999999999999999112e-01 8.500000000000000888e-01 2.500000000000000000e-01 1.500000000000000222e-01 -1.000000000000000000e+00</span><br><span class="line">1.499999999999999112e-01 8.000000000000000444e-01 0.000000000000000000e+00 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">3.999999999999999112e-01 6.499999999999999112e-01 3.499999999999999778e-01 2.000000000000000111e-01 -1.000000000000000000e+00</span><br><span class="line">2.500000000000000000e-01 6.999999999999999556e-01 4.499999999999999556e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">3.500000000000000888e-01 5.000000000000000000e-01 3.000000000000000444e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">3.500000000000000888e-01 6.999999999999999556e-01 3.000000000000000444e-01 1.500000000000000222e-01 -1.000000000000000000e+00</span><br><span class="line">4.500000000000001776e-01 7.500000000000000000e-01 2.500000000000000000e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">4.500000000000001776e-01 6.999999999999999556e-01 1.999999999999999556e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">2.000000000000001776e-01 6.000000000000000888e-01 3.000000000000000444e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">2.500000000000000000e-01 5.500000000000000444e-01 3.000000000000000444e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">5.500000000000002665e-01 6.999999999999999556e-01 2.500000000000000000e-01 1.500000000000000222e-01 -1.000000000000000000e+00</span><br><span class="line">4.500000000000001776e-01 1.049999999999999822e+00 2.500000000000000000e-01 0.000000000000000000e+00 -1.000000000000000000e+00</span><br><span class="line">6.000000000000000888e-01 1.100000000000000089e+00 1.999999999999999556e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">3.000000000000002665e-01 5.500000000000000444e-01 2.500000000000000000e-01 0.000000000000000000e+00 -1.000000000000000000e+00</span><br><span class="line">3.500000000000000888e-01 6.000000000000000888e-01 9.999999999999997780e-02 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">6.000000000000000888e-01 7.500000000000000000e-01 1.500000000000000222e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">3.000000000000002665e-01 5.500000000000000444e-01 2.500000000000000000e-01 0.000000000000000000e+00 -1.000000000000000000e+00</span><br><span class="line">5.000000000000026645e-02 5.000000000000000000e-01 1.500000000000000222e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">3.999999999999999112e-01 6.999999999999999556e-01 2.500000000000000000e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">3.500000000000000888e-01 7.500000000000000000e-01 1.500000000000000222e-01 9.999999999999999167e-02 -1.000000000000000000e+00</span><br><span class="line">1.000000000000000888e-01 1.499999999999999112e-01 1.500000000000000222e-01 9.999999999999999167e-02 -1.000000000000000000e+00</span><br><span class="line">5.000000000000026645e-02 6.000000000000000888e-01 1.500000000000000222e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">3.500000000000000888e-01 7.500000000000000000e-01 3.000000000000000444e-01 2.500000000000000000e-01 -1.000000000000000000e+00</span><br><span class="line">3.999999999999999112e-01 8.999999999999999112e-01 4.499999999999999556e-01 1.500000000000000222e-01 -1.000000000000000000e+00</span><br><span class="line">2.500000000000000000e-01 5.000000000000000000e-01 1.999999999999999556e-01 9.999999999999999167e-02 -1.000000000000000000e+00</span><br><span class="line">3.999999999999999112e-01 8.999999999999999112e-01 3.000000000000000444e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">1.499999999999999112e-01 6.000000000000000888e-01 1.999999999999999556e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">5.000000000000000000e-01 8.500000000000000888e-01 2.500000000000000000e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">3.500000000000000888e-01 6.499999999999999112e-01 1.999999999999999556e-01 5.000000000000000278e-02 -1.000000000000000000e+00</span><br><span class="line">1.350000000000000089e+00 6.000000000000000888e-01 1.850000000000000089e+00 6.499999999999999112e-01 1.000000000000000000e+00</span><br><span class="line">1.050000000000000266e+00 6.000000000000000888e-01 1.750000000000000000e+00 6.999999999999999556e-01 1.000000000000000000e+00</span><br><span class="line">1.300000000000000266e+00 5.500000000000000444e-01 1.950000000000000178e+00 6.999999999999999556e-01 1.000000000000000000e+00</span><br><span class="line">6.000000000000000888e-01 1.499999999999999112e-01 1.500000000000000000e+00 5.999999999999999778e-01 1.000000000000000000e+00</span><br><span class="line">1.100000000000000089e+00 3.999999999999999112e-01 1.799999999999999822e+00 6.999999999999999556e-01 1.000000000000000000e+00</span><br><span class="line">7.000000000000001776e-01 3.999999999999999112e-01 1.750000000000000000e+00 5.999999999999999778e-01 1.000000000000000000e+00</span><br><span class="line">1.000000000000000000e+00 6.499999999999999112e-01 1.850000000000000089e+00 7.500000000000000000e-01 1.000000000000000000e+00</span><br><span class="line">3.000000000000002665e-01 1.999999999999999556e-01 1.149999999999999911e+00 4.500000000000000111e-01 1.000000000000000000e+00</span><br><span class="line">1.149999999999999911e+00 4.499999999999999556e-01 1.799999999999999822e+00 5.999999999999999778e-01 1.000000000000000000e+00</span><br><span class="line">4.500000000000001776e-01 3.500000000000000888e-01 1.449999999999999956e+00 6.499999999999999112e-01 1.000000000000000000e+00</span><br><span class="line">3.500000000000000888e-01 0.000000000000000000e+00 1.250000000000000000e+00 4.500000000000000111e-01 1.000000000000000000e+00</span><br><span class="line">8.000000000000002665e-01 5.000000000000000000e-01 1.600000000000000089e+00 6.999999999999999556e-01 1.000000000000000000e+00</span><br><span class="line">8.500000000000000888e-01 1.000000000000000888e-01 1.500000000000000000e+00 4.500000000000000111e-01 1.000000000000000000e+00</span><br><span class="line">8.999999999999999112e-01 4.499999999999999556e-01 1.850000000000000089e+00 6.499999999999999112e-01 1.000000000000000000e+00</span><br><span class="line">6.499999999999999112e-01 4.499999999999999556e-01 1.300000000000000044e+00 5.999999999999999778e-01 1.000000000000000000e+00</span><br><span class="line">1.200000000000000178e+00 5.500000000000000444e-01 1.700000000000000178e+00 6.499999999999999112e-01 1.000000000000000000e+00</span><br><span class="line">6.499999999999999112e-01 5.000000000000000000e-01 1.750000000000000000e+00 6.999999999999999556e-01 1.000000000000000000e+00</span><br><span class="line">7.500000000000000000e-01 3.500000000000000888e-01 1.549999999999999822e+00 4.500000000000000111e-01 1.000000000000000000e+00</span><br><span class="line">9.500000000000001776e-01 1.000000000000000888e-01 1.750000000000000000e+00 6.999999999999999556e-01 1.000000000000000000e+00</span><br><span class="line">6.499999999999999112e-01 2.500000000000000000e-01 1.449999999999999956e+00 5.000000000000000000e-01 1.000000000000000000e+00</span><br><span class="line">8.000000000000002665e-01 6.000000000000000888e-01 1.899999999999999911e+00 8.499999999999999778e-01 1.000000000000000000e+00</span><br><span class="line">8.999999999999999112e-01 3.999999999999999112e-01 1.500000000000000000e+00 5.999999999999999778e-01 1.000000000000000000e+00</span><br><span class="line">1.000000000000000000e+00 2.500000000000000000e-01 1.950000000000000178e+00 6.999999999999999556e-01 1.000000000000000000e+00</span><br><span class="line">8.999999999999999112e-01 3.999999999999999112e-01 1.850000000000000089e+00 5.499999999999999334e-01 1.000000000000000000e+00</span><br><span class="line">1.050000000000000266e+00 4.499999999999999556e-01 1.649999999999999911e+00 5.999999999999999778e-01 1.000000000000000000e+00</span><br><span class="line">1.149999999999999911e+00 5.000000000000000000e-01 1.700000000000000178e+00 6.499999999999999112e-01 1.000000000000000000e+00</span><br><span class="line">1.250000000000000000e+00 3.999999999999999112e-01 1.899999999999999911e+00 6.499999999999999112e-01 1.000000000000000000e+00</span><br><span class="line">1.200000000000000178e+00 5.000000000000000000e-01 2.000000000000000000e+00 7.999999999999999334e-01 1.000000000000000000e+00</span><br><span class="line">8.500000000000000888e-01 4.499999999999999556e-01 1.750000000000000000e+00 6.999999999999999556e-01 1.000000000000000000e+00</span><br><span class="line">7.000000000000001776e-01 3.000000000000000444e-01 1.250000000000000000e+00 4.500000000000000111e-01 1.000000000000000000e+00</span><br><span class="line">6.000000000000000888e-01 1.999999999999999556e-01 1.399999999999999911e+00 5.000000000000000000e-01 1.000000000000000000e+00</span><br><span class="line">6.000000000000000888e-01 1.999999999999999556e-01 1.350000000000000089e+00 4.500000000000000111e-01 1.000000000000000000e+00</span><br><span class="line">7.500000000000000000e-01 3.500000000000000888e-01 1.449999999999999956e+00 5.499999999999999334e-01 1.000000000000000000e+00</span><br><span class="line">8.500000000000000888e-01 3.500000000000000888e-01 2.049999999999999822e+00 7.500000000000000000e-01 1.000000000000000000e+00</span><br><span class="line">5.500000000000002665e-01 5.000000000000000000e-01 1.750000000000000000e+00 6.999999999999999556e-01 1.000000000000000000e+00</span><br><span class="line">8.500000000000000888e-01 6.999999999999999556e-01 1.750000000000000000e+00 7.500000000000000000e-01 1.000000000000000000e+00</span><br><span class="line">1.200000000000000178e+00 5.500000000000000444e-01 1.850000000000000089e+00 6.999999999999999556e-01 1.000000000000000000e+00</span><br><span class="line">1.000000000000000000e+00 1.499999999999999112e-01 1.700000000000000178e+00 5.999999999999999778e-01 1.000000000000000000e+00</span><br><span class="line">6.499999999999999112e-01 5.000000000000000000e-01 1.549999999999999822e+00 5.999999999999999778e-01 1.000000000000000000e+00</span><br><span class="line">6.000000000000000888e-01 2.500000000000000000e-01 1.500000000000000000e+00 5.999999999999999778e-01 1.000000000000000000e+00</span><br><span class="line">6.000000000000000888e-01 3.000000000000000444e-01 1.700000000000000178e+00 5.499999999999999334e-01 1.000000000000000000e+00</span><br><span class="line">8.999999999999999112e-01 5.000000000000000000e-01 1.799999999999999822e+00 6.499999999999999112e-01 1.000000000000000000e+00</span><br><span class="line">7.500000000000000000e-01 3.000000000000000444e-01 1.500000000000000000e+00 5.499999999999999334e-01 1.000000000000000000e+00</span><br><span class="line">3.500000000000000888e-01 1.499999999999999112e-01 1.149999999999999911e+00 4.500000000000000111e-01 1.000000000000000000e+00</span><br><span class="line">6.499999999999999112e-01 3.500000000000000888e-01 1.600000000000000089e+00 5.999999999999999778e-01 1.000000000000000000e+00</span><br><span class="line">7.000000000000001776e-01 5.000000000000000000e-01 1.600000000000000089e+00 5.499999999999999334e-01 1.000000000000000000e+00</span><br><span class="line">7.000000000000001776e-01 4.499999999999999556e-01 1.600000000000000089e+00 5.999999999999999778e-01 1.000000000000000000e+00</span><br><span class="line">9.500000000000001776e-01 4.499999999999999556e-01 1.649999999999999911e+00 5.999999999999999778e-01 1.000000000000000000e+00</span><br><span class="line">3.999999999999999112e-01 2.500000000000000000e-01 1.000000000000000000e+00 5.000000000000000000e-01 1.000000000000000000e+00</span><br><span class="line">7.000000000000001776e-01 3.999999999999999112e-01 1.549999999999999822e+00 5.999999999999999778e-01 1.000000000000000000e+00</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="逐个代码剖析"><a href="#逐个代码剖析" class="headerlink" title="逐个代码剖析"></a>逐个代码剖析</h3><h4 id="1-项目所需头文件"><a href="#1-项目所需头文件" class="headerlink" title="1. 项目所需头文件"></a>1. 项目所需头文件</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pennyLane 是一个开源的量子计算库，旨在使量子计算与机器学习、优化和其他                             经典计算领域结合起来。</span></span><br><span class="line"><span class="keyword">import</span> pennylane <span class="keyword">as</span> qml  </span><br><span class="line"></span><br><span class="line"><span class="comment"># NumPy 是 Python 中用于数值计算的核心库，提供了高效的多维数组操作、矩阵运算、线性代数功能、傅里叶变换、随机数生成等。</span></span><br><span class="line"><span class="keyword">from</span> pennylane <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># NesterovMomentumOptimizer 是 PennyLane 提供的一种优化器，通常用于变分量子算法（VQA）中。它实现了 Nesterov 动量优化方法，该方法是一种基于梯度下降的加速优化算法，用于寻找损失函数的最小值。</span></span><br><span class="line"><span class="keyword">from</span> pennylane.optimize <span class="keyword">import</span> NesterovMomentumOptimizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># arcsin 是 NumPy 库中的一个数学函数，表示反正弦（逆正弦）函数。给定一个值，它返回该值的反正弦（即角度）。其定义为 arcsin(x)，返回值为角度（弧度制）。</span></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> arcsin</span><br></pre></td></tr></table></figure>

<h4 id="2-所使用的量子设备"><a href="#2-所使用的量子设备" class="headerlink" title="2.所使用的量子设备"></a>2.所使用的量子设备</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dev = qml.device(<span class="string">&#x27;lightning.qubit&#x27;</span>, wires=(<span class="number">0</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<p>**<code>qml.device</code>**：这是 PennyLane 中用于创建量子设备的函数。通过它，可以指定你要使用的量子硬件或模拟器。</p>
<p>**<code>&#39;lightning.qubit&#39;</code>**：这里选择了 <strong>lightning.qubit</strong> 作为设备类型。<code>lightning.qubit</code> 是 PennyLane 提供的一个高效的模拟器，用于在 CPU 上模拟量子计算。它是基于 <strong>Lightning</strong> 框架开发的，速度较快，适合进行小规模的量子计算仿真。</p>
<ul>
<li>如果你想要使用实际的量子硬件（如 <strong>IBM Q</strong>、<strong>Rigetti</strong> 等），可以通过提供对应的设备名（例如 <code>&#39;ibmq&#39;</code>）来选择硬件设备。</li>
</ul>
<p>**<code>wires=(0, 1)</code>**：这表示量子设备有两个量子比特（qubits），分别位于 <strong>wire 0</strong> 和 <strong>wire 1</strong>。在 PennyLane 中，<code>wires</code> 参数指定了量子比特的数量和它们的索引。这里创建的是一个有两个量子比特的设备。</p>
<h4 id="3-计算输入数组的角度值"><a href="#3-计算输入数组的角度值" class="headerlink" title="3.计算输入数组的角度值"></a>3.计算输入数组的角度值</h4><p>为后面量子线路旋转角度做准备</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_angles</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="comment"># 这三行代码计算了三个角度值，有反正弦计算得到</span></span><br><span class="line">    <span class="comment"># 计算x[0]和x[1]的平方和的反正弦值  1e-12避免除0错误</span></span><br><span class="line">    beta0 = <span class="number">2</span> * np.arcsin(np.sqrt(x[<span class="number">1</span>] ** <span class="number">2</span>) / np.sqrt(x[<span class="number">0</span>] ** <span class="number">2</span> + x[<span class="number">1</span>] ** <span class="number">2</span> + <span class="number">1e-12</span>))</span><br><span class="line">    <span class="comment"># 计算x[2]和x[3]的平方和的反正弦值  1e-12避免除0错误</span></span><br><span class="line">    beta1 = <span class="number">2</span> * np.arcsin(np.sqrt(x[<span class="number">3</span>] ** <span class="number">2</span>) / np.sqrt(x[<span class="number">2</span>] ** <span class="number">2</span> + x[<span class="number">3</span>] ** <span class="number">2</span> + <span class="number">1e-12</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># beta2 是通过计算从 x[2] 到 x[n]（即 x[2:]）的欧几里得范数与 x 数组的总范数的比值，之后取反     # 正弦并乘以 2</span></span><br><span class="line">    beta2 = <span class="number">2</span> * np.arcsin(np.linalg.norm(x[<span class="number">2</span>:]) / np.linalg.norm(x))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 最终返回一个数组，包含了五个计算出的角度值。这里的 beta1 和 beta0 的值被分别取了正负一半。</span></span><br><span class="line">    <span class="keyword">return</span> np.array([beta2, -beta1 / <span class="number">2</span>, beta1 / <span class="number">2</span>, -beta0 / <span class="number">2</span>, beta0 / <span class="number">2</span>])</span><br></pre></td></tr></table></figure>

<h4 id="4-量子线路准备"><a href="#4-量子线路准备" class="headerlink" title="4.量子线路准备"></a>4.量子线路准备</h4><p><img src="/./../../images/%E9%A1%B9%E7%9B%AE%E5%9B%BE/%E9%87%8F%E5%AD%90%E7%B4%AB%E8%96%87%E8%8A%B1/04.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">state_preparation</span>(<span class="params">a</span>):</span><br><span class="line">    qml.RY(a[<span class="number">0</span>], wires=<span class="number">0</span>)  </span><br><span class="line"></span><br><span class="line">    qml.CNOT(wires=[<span class="number">0</span>, <span class="number">1</span>])  </span><br><span class="line">    qml.RY(a[<span class="number">1</span>], wires=<span class="number">1</span>)  </span><br><span class="line">    qml.CNOT(wires=[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">    qml.RY(a[<span class="number">2</span>], wires=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    qml.PauliX(wires=<span class="number">0</span>)</span><br><span class="line">    qml.CNOT(wires=[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">    qml.RY(a[<span class="number">3</span>], wires=<span class="number">1</span>)</span><br><span class="line">    qml.CNOT(wires=[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">    qml.RY(a[<span class="number">4</span>], wires=<span class="number">1</span>)</span><br><span class="line">    qml.PauliX(wires=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>（1）**<code>RY(a[0], wires=0)</code>**：这行代码给第 0 号量子比特应用了一个旋转门 <code>RY</code>，其角度为 <code>a[0]</code>。<code>RY(θ)</code> 是绕 Y 轴旋转的门，作用是改变量子比特的相位。</p>
<p>（2）**<code>qml.CNOT(wires=[0, 1])</code>**：应用一个 <strong>CNOT</strong> 门，控制比特为量子比特 0，目标比特为量子比特 1。该操作将 <code>q[1]</code> 与 <code>q[0]</code> 纠缠。</p>
<p>（3）**<code>qml.RY(a[1], wires=1)</code>**：这行代码给第 1 号量子比特应用了一个 <code>RY</code> 门，旋转角度为 <code>a[1]</code>。</p>
<p>（4）**<code>qml.PauliX(wires=0)</code>**：这行代码给第 0 号量子比特应用了一个 Pauli X 门，Pauli X 门相当于经典的 NOT 门，会将量子比特从 |0&gt; 状态翻转为 |1&gt; 状态，反之亦然。</p>
<p>（5）<strong>CNOT 和 RY 的重复应用</strong>：</p>
<p>​        该部分代码与前面类似，通过 CNOT 和 RY 门进一步调整量子比特之间的关系，可能用于将量子信息纠缠。</p>
<p>（6）<strong>重复的 <code>CNOT</code> 和 <code>RY</code> 操作</strong>：</p>
<p>​        第 1 号量子比特的旋转角度分别为 <code>a[2]</code> 和 <code>a[4]</code>，并且应用了 CNOT 门，这可能用于在两个量子比特之间建立进一步的量子纠缠。</p>
<h4 id="5-测试设计的量子线路是否有效"><a href="#5-测试设计的量子线路是否有效" class="headerlink" title="5.测试设计的量子线路是否有效"></a>5.测试设计的量子线路是否有效</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个输入值</span></span><br><span class="line">x = np.array([<span class="number">0.53896774</span>, <span class="number">0.79503606</span>, <span class="number">0.27826503</span>, <span class="number">0.0</span>], requires_grad=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 对输入值转换成角度</span></span><br><span class="line">ang = get_angles(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此处为量子结点，后续的量子函数将在已经定义好的dev上运行</span></span><br><span class="line"><span class="meta">@qml.qnode(<span class="params">dev</span>)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用计算出的角度来对量子门的旋转角度进行处理</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">angles</span>):</span><br><span class="line">    state_preparation(angles)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> qml.state()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">state = test(ang)</span><br><span class="line"></span><br><span class="line"><span class="comment"># np.round 是 NumPy 库中的一个函数，用于将数字或数组的元素四舍五入到指定的小数位数。</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x               : &quot;</span>, np.<span class="built_in">round</span>(x, <span class="number">6</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;angles          : &quot;</span>, np.<span class="built_in">round</span>(ang, <span class="number">6</span>))</span><br><span class="line"><span class="comment"># 这行代码的作用是输出量子状态的幅度向量的实部</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;amplitude vector: &quot;</span>, np.<span class="built_in">round</span>(np.real(state), <span class="number">6</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;该方法计算了正确的角度以及准备所需要的态&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>输出结果如下:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x         :  [0.538968 0.795036 0.278265 0.      ]</span><br><span class="line">angles          :  [ 0.563975 -0.        0.       -0.975046  0.975046]</span><br><span class="line">amplitude vector:  [ 0.538968  0.795036  0.278265 -0.      ]</span><br><span class="line">该方法计算了正确的角度以及准备所需要的态</span><br></pre></td></tr></table></figure>

<h4 id="6-一些测试函数"><a href="#6-一些测试函数" class="headerlink" title="6.一些测试函数"></a>6.一些测试函数</h4><p>（1）计算 均方误差 (MSE)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">square_loss</span>(<span class="params">labels, predictions</span>):</span><br><span class="line">    <span class="comment"># We use a call to qml.math.stack to allow subtracting the arrays directly</span></span><br><span class="line">    <span class="keyword">return</span> np.mean((labels - qml.math.stack(predictions)) ** <span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<p><strong>输入参数：</strong></p>
<ul>
<li>**<code>labels</code>**：表示真实标签或实际值。通常是一个 NumPy 数组或张量，代表真实的目标值。</li>
<li>**<code>predictions</code>**：表示模型的预测值，通常是来自模型或量子电路的预测值。这可能是一个列表或数组。</li>
</ul>
<p>**<code>qml.math.stack(predictions)</code>**：</p>
<ul>
<li><code>qml.math.stack</code> 用于确保 <code>predictions</code> 数组的格式是可以直接与 <code>labels</code> 相减的。这通常是为了确保输入数据的统一性，尤其是在量子计算框架中，预测结果可能以不同的格式返回（例如列表或张量）。</li>
<li>如果 <code>predictions</code> 已经是一个标准的 NumPy 数组，这一步可能不必要，但在使用 PennyLane 等量子计算库时，这样做可以确保兼容性，避免类型或结构的冲突。</li>
</ul>
<p>**(labels - qml.math.stack(predictions))&#96;**：</p>
<ul>
<li>这是真实标签和预测值之间的误差项（即差值）。它是逐元素计算的（每个 <code>labels</code> 和 <code>predictions</code> 数组中对应位置的元素相减）。</li>
</ul>
<p>**<code>(labels - qml.math.stack(predictions)) \** 2</code>**：</p>
<ul>
<li>对误差进行逐元素平方，这是均方误差（MSE）计算中的关键步骤。平方误差可以确保无论误差是正还是负，都会对损失值产生积极的贡献，并且较大的误差会受到更大的惩罚。</li>
</ul>
<p> **np.mean(…)&#96;**：</p>
<ul>
<li><code>np.mean</code> 计算所有平方误差的平均值，这就是 **均方误差 (MSE)**，它提供一个代表预测值和实际值之间总体误差的单一数值。</li>
</ul>
<p>（2）准确度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">labels, predictions</span>):</span><br><span class="line">    acc = <span class="built_in">sum</span>(<span class="built_in">abs</span>(l - p) &lt; <span class="number">1e-5</span> <span class="keyword">for</span> l, p <span class="keyword">in</span> <span class="built_in">zip</span>(labels, predictions))</span><br><span class="line">    acc = acc / <span class="built_in">len</span>(labels)</span><br><span class="line">    <span class="keyword">return</span> acc</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>[1]<strong><code>labels</code> 和 <code>predictions</code>：</strong></p>
<ul>
<li>**<code>labels</code>**：表示真实的标签或目标值，通常是一个 NumPy 数组或列表。</li>
<li>**<code>predictions</code>**：表示模型的预测值，通常是来自模型或量子电路的预测结果，也可以是一个数组或列表。</li>
</ul>
<p>[2]<strong><code>zip(labels, predictions)</code>：</strong></p>
<ul>
<li><code>zip</code> 函数将 <code>labels</code> 和 <code>predictions</code> 中的对应元素打包成一个个元组，例如 <code>(l1, p1), (l2, p2), ...</code>。这样可以便于后续逐对比对每个标签和预测值。</li>
</ul>
<p>[3]<strong><code>abs(l - p) &lt; 1e-5</code>：</strong></p>
<ul>
<li>对每一对 <code>(l, p)</code>（即真实标签和预测值）进行比较，计算它们的差值并判断差值是否小于 1×10−51 \times 10^{-5}1×10−5。</li>
<li>这里使用了 <code>abs</code> 函数来计算它们的绝对差值，<code>1e-5</code> 是一个小的容差，用于处理可能的数值精度误差。</li>
<li>如果绝对差值小于 <code>1e-5</code>，就认为这次预测是正确的，否则认为预测错误。</li>
</ul>
<p>[4]<strong><code>sum(abs(l - p) &lt; 1e-5 for l, p in zip(labels, predictions))</code>：</strong></p>
<ul>
<li><code>sum()</code> 函数计算 <code>True</code> 的数量。由于 <code>True</code> 被当作 <code>1</code> 处理，<code>False</code> 被当作 <code>0</code>，所以这个表达式最终会返回预测正确的个数。</li>
</ul>
<p>[5]<strong><code>acc = acc / len(labels)</code>：</strong></p>
<ul>
<li>将预测正确的个数除以标签的总数，得到准确率。这个值是一个介于 0 和 1 之间的浮动值，表示模型预测的准确性。</li>
</ul>
<p>[6]<strong><code>return acc</code>：</strong></p>
<ul>
<li>返回最终的准确率值。</li>
</ul>
<p>（3）成本函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">cost</span>(<span class="params">weights, bias, X, Y</span>):</span><br><span class="line">    <span class="comment"># Transpose the batch of input data in order to make the indexing</span></span><br><span class="line">    <span class="comment"># in state_preparation work</span></span><br><span class="line">    predictions = variational_classifier(weights, bias, X.T) <span class="comment"># 计算出预测值</span></span><br><span class="line">    <span class="keyword">return</span> square_loss(Y, predictions) <span class="comment"># 返回实际值和预测值的均方误差</span></span><br></pre></td></tr></table></figure>

<h4 id="7-重构量子层"><a href="#7-重构量子层" class="headerlink" title="7.重构量子层"></a>7.重构量子层</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">layer</span>(<span class="params">layer_weights</span>):</span><br><span class="line">    <span class="keyword">for</span> wire <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        qml.Rot(*layer_weights[wire], wires=wire)</span><br><span class="line">    qml.CNOT(wires=[<span class="number">0</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<h3 id="解释："><a href="#解释：" class="headerlink" title="解释："></a>解释：</h3><ol>
<li>**<code>layer_weights</code>**：<ul>
<li><code>layer_weights</code> 是一个包含量子比特旋转角度的输入列表或数组。这个参数应该是一个长度为 2 的列表或数组，<strong>每个元素包含三个旋转角度（<code>θ</code>, <code>φ</code>, <code>λ</code>）</strong>，这三个角度将被传递给 <code>qml.Rot</code> 门来定义旋转。</li>
</ul>
</li>
<li>**<code>for wire in range(2)</code>**：<ul>
<li>这个 <code>for</code> 循环遍历量子比特 <code>0</code> 和 <code>1</code>（即量子线路中的两个量子比特）。在这个循环中，我们对每个量子比特应用旋转门。</li>
</ul>
</li>
<li>**<code>qml.Rot(\*layer_weights[wire], wires=wire)</code>**：<ul>
<li><code>qml.Rot</code> 是一个量子门，表示对指定量子比特的旋转。<code>*layer_weights[wire]</code> 将从 <code>layer_weights</code> 中取出一个三元组，分别对应旋转门的三个参数 <code>θ</code>, <code>φ</code>, 和 <code>λ</code>，这些参数决定了旋转的角度。</li>
<li><code>wires=wire</code> 指定了旋转门作用的量子比特，<code>wire</code> 在这里取值 0 或 1。</li>
</ul>
</li>
<li>**<code>qml.CNOT(wires=[0, 1])</code>**：<ul>
<li>在两个旋转门之后，<code>qml.CNOT</code> 门（受控非门）被应用在量子比特 <code>0</code> 和 <code>1</code> 上，其中量子比特 0 是控制比特，量子比特 1 是目标比特。</li>
<li>如果控制比特（量子比特 0）处于状态 <code>|1⟩</code>，则会翻转目标比特（量子比特 1）。这是量子计算中的一个常见操作，广泛用于量子纠缠生成和量子线路中的条件操作。</li>
</ul>
</li>
</ol>
<h4 id="8-全连接层和变分量子分类器"><a href="#8-全连接层和变分量子分类器" class="headerlink" title="8.全连接层和变分量子分类器"></a>8.全连接层和变分量子分类器</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@qml.qnode(<span class="params">dev</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">circuit</span>(<span class="params">weights, x</span>):</span><br><span class="line">    state_preparation(x) <span class="comment"># 得到量子比特的初始态</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> layer_weights <span class="keyword">in</span> weights:</span><br><span class="line">        layer(layer_weights)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> qml.expval(qml.PauliZ(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">variational_classifier</span>(<span class="params">weights, bias, x</span>):</span><br><span class="line">    <span class="keyword">return</span> circuit(weights, x) + bias</span><br></pre></td></tr></table></figure>

<h3 id="解释：-1"><a href="#解释：-1" class="headerlink" title="解释："></a>解释：</h3><ol>
<li><strong>装饰器 <code>@qml.qnode(dev)</code></strong></li>
</ol>
<ul>
<li><code>@qml.qnode(dev)</code> 是 Pennylane 的一个装饰器，表示该函数是一个量子节点（QNode）。在 Pennylane 中，QNode 是量子电路的封装函数，可以接受输入数据（如 <code>x</code> 和 <code>weights</code>），并返回量子电路的输出结果。</li>
<li><code>dev</code> 是你量子设备的实例，通常是一个模拟设备或者量子硬件的接口，定义了该电路的执行环境（例如是一个模拟器或者一个量子硬件设备）。</li>
</ul>
<ol start="2">
<li><strong><code>circuit</code> 函数</strong></li>
</ol>
<p><code>circuit</code> 函数的输入参数是：</p>
<ul>
<li><strong><code>weights</code></strong>: 该参数是一个列表，其中包含了每一层的旋转门角度，通常是量子神经网络中的可调参数（例如，量子电路中的旋转角度）。</li>
<li><strong><code>x</code></strong>: 输入数据，通常是一个特征向量。<code>x</code> 将被用于量子电路中的状态准备过程。</li>
</ul>
<ol start="3">
<li><strong><code>state_preparation(x)</code></strong></li>
</ol>
<ul>
<li>这个函数调用是用来初始化量子比特的状态。它将根据输入 <code>x</code> 中的数据来设置量子比特的初始状态。我们之前看到过 <code>state_preparation</code> 函数，它应用了旋转门和 CNOT 门来生成<strong>量子比特的初始状态</strong>。</li>
</ul>
<ol start="4">
<li><strong><code>for layer_weights in weights:</code></strong></li>
</ol>
<ul>
<li>这个循环遍历了所有的层的旋转角度。每一层的旋转角度（<code>layer_weights</code>）都会传递给 <code>layer</code> 函数，<code>layer</code> 函数会对量子比特应用旋转门和 CNOT 门，构建出量子电路的各层。</li>
</ul>
<ol start="5">
<li><strong><code>qml.expval(qml.PauliZ(0))</code></strong></li>
</ol>
<ul>
<li><p>这是量子电路的输出部分。在量子计算中，<code>qml.expval</code> 用于计算量子比特的期望值。<code>qml.PauliZ(0)</code> 表示对量子比特 0 应用 Pauli-Z 算符。</p>
</li>
<li><p>Pauli-Z 算符</p>
<p> 是量子计算中一种常见的单量子比特算符，它作用在量子比特上时，将其状态 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">|0⟩</span><br></pre></td></tr></table></figure>

<p> 保持不变，而将 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">|1⟩</span><br></pre></td></tr></table></figure>

<p> 状态翻转。其矩阵表示为：<br>$$<br>Z &#x3D; \begin{pmatrix} 1 &amp; 0 \ 0 &amp; -1 \end{pmatrix}<br>$$</p>
<ul>
<li><code>qml.expval(qml.PauliZ(0))</code> 计算的是量子比特 0 的 Pauli-Z 算符的期望值。其结果为 +1 或 -1，表示量子比特 0 的最终状态是 <code>|0⟩</code> 还是 <code>|1⟩</code>。</li>
</ul>
</li>
</ul>
<h4 id="9-数据"><a href="#9-数据" class="headerlink" title="9.数据"></a>9.数据</h4><p>我们加载 Iris 数据集。为了将<strong>输入编码为量子态的振幅</strong>，需要进行一些预处理。我们将通过两个所谓的“潜在维度”来增加数据点，<strong>使填充数据点的大小与量子设备中的状态向量的大小相匹配</strong>。然后我们需要对<strong>数据点进行归一化</strong>，最后，我们<strong>使用<code>get_angles</code>上面定义的函数将输入 x 转换为旋转角度</strong>。</p>
<p>数据预处理应始终考虑到问题；例如，如果我们不添加任何潜在维度，则规范化会抹去有关向量长度的任何信息，并且该特征分隔的类别将无法区分。</p>
<h5 id="（1）数据扩维度来匹配相应的态"><a href="#（1）数据扩维度来匹配相应的态" class="headerlink" title="（1）数据扩维度来匹配相应的态"></a>（1）数据扩维度来匹配相应的态</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">data = np.loadtxt(<span class="string">&quot;iris_classes1and2_scaled.txt&quot;</span>)</span><br><span class="line"><span class="comment"># 取前两列数据</span></span><br><span class="line">X = data[:, <span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;First X sample (original)  : <span class="subst">&#123;X[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># pad the vectors to size 2^2=4 with constant values</span></span><br><span class="line">padding = np.ones((<span class="built_in">len</span>(X), <span class="number">2</span>)) * <span class="number">0.1</span></span><br><span class="line">X_pad = np.c_[X, padding]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;First X sample (padded)    : <span class="subst">&#123;X_pad[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="解释：-2"><a href="#解释：-2" class="headerlink" title="解释："></a>解释：</h3><ol>
<li><strong><code>padding = np.ones((len(X), 2)) \* 0.1</code></strong></li>
</ol>
<ul>
<li>这行代码创建了一个形状为 <code>(len(X), 2)</code> 的数组，其中 <code>len(X)</code> 是输入数据 <code>X</code> 中样本的数量，2 是目标维度差异，表示每个样本需要填充的维度大小。</li>
<li><code>np.ones((len(X), 2))</code> 生成一个所有元素为 1 的二维数组。</li>
<li>然后，通过 <code>* 0.1</code> 将数组中的所有值乘以 0.1，从而生成一个填充值为 0.1 的数组。这是填充操作，用来扩展每个输入样本的维度。</li>
</ul>
<ol start="2">
<li><strong><code>X_pad = np.c_[X, padding]</code></strong></li>
</ol>
<ul>
<li><code>np.c_[X, padding]</code> 使用 <code>np.c_</code>（<strong>一个用于按列合并数组的快捷方式</strong>）将原始数据 <code>X</code> 和填充后的数组 <code>padding</code> 进行按列拼接。</li>
<li><code>X</code> 是输入数据矩阵，它的每一行表示一个样本，列表示特征。</li>
<li><strong>通过拼接 <code>padding</code>，每个样本的特征数（维度）从原来的大小增加到 4（原大小加上了填充的 2 个维度）。<code>X_pad</code> 是填充后的数据。</strong></li>
</ul>
<ol start="3">
<li><strong><code>print(f&quot;First X sample (padded) : &#123;X_pad[0]&#125;&quot;)</code></strong></li>
</ol>
<ul>
<li><strong>这行代码打印填充后的 <code>X</code> 的第一个样本（即 <code>X_pad[0]</code>）</strong>。打印时，<code>f</code> 字符串格式化用于显示填充后的样本</li>
</ul>
<h5 id="（2）归一化处理"><a href="#（2）归一化处理" class="headerlink" title="（2）归一化处理"></a>（2）归一化处理</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># normalize each input</span></span><br><span class="line">normalization = np.sqrt(np.<span class="built_in">sum</span>(X_pad**<span class="number">2</span>, -<span class="number">1</span>))</span><br><span class="line">X_norm = (X_pad.T / normalization).T</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;First X sample (normalized): <span class="subst">&#123;X_norm[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<ol>
<li><em><strong><code>normalization = np.sqrt(np.sum(X_pad\**2, -1))</code></strong></em></li>
</ol>
<ul>
<li><p><strong>这行代码的作用是计算每个样本的欧几里得范数（L2 范数），用于归一化</strong>。</p>
</li>
<li><p><code>X_pad**2</code> 对 <code>X_pad</code> 数组中的每个元素进行平方。</p>
</li>
<li><p><code>np.sum(X_pad**2, -1)</code> 沿着每个样本的最后一个维度（即特征维度）求和。对于每个样本，它会计算特征平方的总和：<br>$$<br>\text{sum of squares} &#x3D; \sum_{i&#x3D;1}^n<br>$$<br>xi 是样本的各个特征。</p>
</li>
<li><p><code>np.sqrt()</code> 对每个样本的平方和结果取平方根，得到每个样本的欧几里得范数（即每个样本的模长）：</p>
<p>$$<br>\text{norm} &#x3D; \sqrt{\sum_{i&#x3D;1}^n x_i^2}<br>$$</p>
</li>
</ul>
<ol start="2">
<li><em><strong><code>X_norm = (X_pad.T / normalization).T</code></strong></em></li>
</ol>
<ul>
<li><p><code>X_pad.T</code> 对 <code>X_pad</code> 进行转置，使得样本变成列，特征变成行。</p>
</li>
<li><p>然后，将每个样本（即每一列）除以对应的欧几里得范数 <code>normalization</code>，实现归一化。归一化的公式是：<br>$$<br>\hat{x}_i &#x3D; \frac{x_i}{|x|}<br>$$</p>
<p>$$<br>其中 𝑥^𝑖是归一化后的样本，𝑥𝑖 是原始样本，∥𝑥∥ 是该样本的欧几里得范数。<br>$$</p>
</li>
<li><p><code>X_pad.T / normalization</code> 这样操作时，每个特征都被对应的欧几里得范数归一化。</p>
</li>
<li><p><code>T</code> 将结果再转置回来，恢复成原来的样本和特征的形状。</p>
</li>
</ul>
<ol start="3">
<li><em><strong><code>print(f&quot;First X sample (normalized): &#123;X_norm[0]&#125;&quot;)</code></strong></em></li>
</ol>
<ul>
<li>这行代码打印归一化后的 <code>X_norm</code> 的第一个样本（即 <code>X_norm[0]</code>）。</li>
<li>输出的样本已经经过了归一化处理，每个样本的特征值将处于一个单位范数内。</li>
</ul>
<h4 id="10-数据处理后可视化处理"><a href="#10-数据处理后可视化处理" class="headerlink" title="10.数据处理后可视化处理"></a>10.数据处理后可视化处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>][Y == <span class="number">1</span>], X[:, <span class="number">1</span>][Y == <span class="number">1</span>], c=<span class="string">&quot;b&quot;</span>, marker=<span class="string">&quot;o&quot;</span>, ec=<span class="string">&quot;k&quot;</span>)</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>][Y == -<span class="number">1</span>], X[:, <span class="number">1</span>][Y == -<span class="number">1</span>], c=<span class="string">&quot;r&quot;</span>, marker=<span class="string">&quot;o&quot;</span>, ec=<span class="string">&quot;k&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Original data&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/./../../images/%E9%A1%B9%E7%9B%AE%E5%9B%BE/%E9%87%8F%E5%AD%90%E7%B4%AB%E8%96%87%E8%8A%B1/01.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.figure()</span><br><span class="line">dim1 = <span class="number">0</span></span><br><span class="line">dim2 = <span class="number">1</span></span><br><span class="line">plt.scatter(X_norm[:, dim1][Y == <span class="number">1</span>], X_norm[:, dim2][Y == <span class="number">1</span>], c=<span class="string">&quot;b&quot;</span>, marker=<span class="string">&quot;o&quot;</span>, ec=<span class="string">&quot;k&quot;</span>)</span><br><span class="line">plt.scatter(X_norm[:, dim1][Y == -<span class="number">1</span>], X_norm[:, dim2][Y == -<span class="number">1</span>], c=<span class="string">&quot;r&quot;</span>, marker=<span class="string">&quot;o&quot;</span>, ec=<span class="string">&quot;k&quot;</span>)</span><br><span class="line">plt.title(<span class="string">f&quot;Padded and normalised data (dims <span class="subst">&#123;dim1&#125;</span> and <span class="subst">&#123;dim2&#125;</span>)&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/./../../images/%E9%A1%B9%E7%9B%AE%E5%9B%BE/%E9%87%8F%E5%AD%90%E7%B4%AB%E8%96%87%E8%8A%B1/02.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.figure()</span><br><span class="line">dim1 = <span class="number">0</span></span><br><span class="line">dim2 = <span class="number">3</span></span><br><span class="line">plt.scatter(features[:, dim1][Y == <span class="number">1</span>], features[:, dim2][Y == <span class="number">1</span>], c=<span class="string">&quot;b&quot;</span>, marker=<span class="string">&quot;o&quot;</span>, ec=<span class="string">&quot;k&quot;</span>)</span><br><span class="line">plt.scatter(features[:, dim1][Y == -<span class="number">1</span>], features[:, dim2][Y == -<span class="number">1</span>], c=<span class="string">&quot;r&quot;</span>, marker=<span class="string">&quot;o&quot;</span>, ec=<span class="string">&quot;k&quot;</span>)</span><br><span class="line">plt.title(<span class="string">f&quot;Feature vectors (dims <span class="subst">&#123;dim1&#125;</span> and <span class="subst">&#123;dim2&#125;</span>)&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/./../../images/%E9%A1%B9%E7%9B%AE%E5%9B%BE/%E9%87%8F%E5%AD%90%E7%B4%AB%E8%96%87%E8%8A%B1/03.png"></p>
<h4 id="11-泛化"><a href="#11-泛化" class="headerlink" title="11.泛化"></a>11.泛化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">num_data = <span class="built_in">len</span>(Y)</span><br><span class="line">num_train = <span class="built_in">int</span>(<span class="number">0.75</span> * num_data)</span><br><span class="line">index = np.random.permutation(<span class="built_in">range</span>(num_data))</span><br><span class="line">feats_train = features[index[:num_train]]</span><br><span class="line">Y_train = Y[index[:num_train]]</span><br><span class="line">feats_val = features[index[num_train:]]</span><br><span class="line">Y_val = Y[index[num_train:]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># We need these later for plotting</span></span><br><span class="line">X_train = X[index[:num_train]]</span><br><span class="line">X_val = X[index[num_train:]]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="12-优化"><a href="#12-优化" class="headerlink" title="12.优化"></a>12.优化</h4><p>初始化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">num_qubits = <span class="number">2</span></span><br><span class="line">num_layers = <span class="number">6</span></span><br><span class="line"></span><br><span class="line">weights_init = <span class="number">0.01</span> * np.random.randn(num_layers, num_qubits, <span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">bias_init = np.array(<span class="number">0.0</span>, requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>导入优化器来最小化成本</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">opt = NesterovMomentumOptimizer(<span class="number">0.01</span>)</span><br><span class="line">batch_size = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># train the variational classifier</span></span><br><span class="line">weights = weights_init</span><br><span class="line">bias = bias_init</span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">60</span>):</span><br><span class="line">    <span class="comment"># Update the weights by one optimizer step</span></span><br><span class="line">    batch_index = np.random.randint(<span class="number">0</span>, num_train, (batch_size,))</span><br><span class="line">    feats_train_batch = feats_train[batch_index]</span><br><span class="line">    Y_train_batch = Y_train[batch_index]</span><br><span class="line">    weights, bias, _, _ = opt.step(cost, weights, bias, feats_train_batch, Y_train_batch)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute predictions on train and validation set</span></span><br><span class="line">    predictions_train = np.sign(variational_classifier(weights, bias, feats_train.T))</span><br><span class="line">    predictions_val = np.sign(variational_classifier(weights, bias, feats_val.T))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute accuracy on train and validation set</span></span><br><span class="line">    acc_train = accuracy(Y_train, predictions_train)</span><br><span class="line">    acc_val = accuracy(Y_val, predictions_val)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (it + <span class="number">1</span>) % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">        _cost = cost(weights, bias, features, Y)</span><br><span class="line">        <span class="built_in">print</span>(</span><br><span class="line">            <span class="string">f&quot;Iter: <span class="subst">&#123;it + <span class="number">1</span>:5d&#125;</span> | Cost: <span class="subst">&#123;_cost:<span class="number">0.7</span>f&#125;</span> | &quot;</span></span><br><span class="line">            <span class="string">f&quot;Acc train: <span class="subst">&#123;acc_train:<span class="number">0.7</span>f&#125;</span> | Acc validation: <span class="subst">&#123;acc_val:<span class="number">0.7</span>f&#125;</span>&quot;</span></span><br><span class="line">        )</span><br></pre></td></tr></table></figure>

<h4 id="13-绘制-Iris-数据集前两个维的变分分类器的连续输出"><a href="#13-绘制-Iris-数据集前两个维的变分分类器的连续输出" class="headerlink" title="13.绘制 Iris 数据集前两个维的变分分类器的连续输出"></a>13.绘制 Iris 数据集前两个维的变分分类器的连续输出</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">plt.figure()</span><br><span class="line">cm = plt.cm.RdBu</span><br><span class="line"></span><br><span class="line"><span class="comment"># make data for decision regions</span></span><br><span class="line">xx, yy = np.meshgrid(np.linspace(<span class="number">0.0</span>, <span class="number">1.5</span>, <span class="number">30</span>), np.linspace(<span class="number">0.0</span>, <span class="number">1.5</span>, <span class="number">30</span>))</span><br><span class="line">X_grid = [np.array([x, y]) <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(xx.flatten(), yy.flatten())]</span><br><span class="line"></span><br><span class="line"><span class="comment"># preprocess grid points like data inputs above</span></span><br><span class="line">padding = <span class="number">0.1</span> * np.ones((<span class="built_in">len</span>(X_grid), <span class="number">2</span>))</span><br><span class="line">X_grid = np.c_[X_grid, padding]  <span class="comment"># pad each input</span></span><br><span class="line">normalization = np.sqrt(np.<span class="built_in">sum</span>(X_grid**<span class="number">2</span>, -<span class="number">1</span>))</span><br><span class="line">X_grid = (X_grid.T / normalization).T  <span class="comment"># normalize each input</span></span><br><span class="line">features_grid = np.array([get_angles(x) <span class="keyword">for</span> x <span class="keyword">in</span> X_grid])  <span class="comment"># angles are new features</span></span><br><span class="line">predictions_grid = variational_classifier(weights, bias, features_grid.T)</span><br><span class="line">Z = np.reshape(predictions_grid, xx.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot decision regions</span></span><br><span class="line">levels = np.arange(-<span class="number">1</span>, <span class="number">1.1</span>, <span class="number">0.1</span>)</span><br><span class="line">cnt = plt.contourf(xx, yy, Z, levels=levels, cmap=cm, alpha=<span class="number">0.8</span>, extend=<span class="string">&quot;both&quot;</span>)</span><br><span class="line">plt.contour(xx, yy, Z, levels=[<span class="number">0.0</span>], colors=(<span class="string">&quot;black&quot;</span>,), linestyles=(<span class="string">&quot;--&quot;</span>,), linewidths=(<span class="number">0.8</span>,))</span><br><span class="line">plt.colorbar(cnt, ticks=[-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot data</span></span><br><span class="line"><span class="keyword">for</span> color, label <span class="keyword">in</span> <span class="built_in">zip</span>([<span class="string">&quot;b&quot;</span>, <span class="string">&quot;r&quot;</span>], [<span class="number">1</span>, -<span class="number">1</span>]):</span><br><span class="line">    plot_x = X_train[:, <span class="number">0</span>][Y_train == label]</span><br><span class="line">    plot_y = X_train[:, <span class="number">1</span>][Y_train == label]</span><br><span class="line">    plt.scatter(plot_x, plot_y, c=color, marker=<span class="string">&quot;o&quot;</span>, ec=<span class="string">&quot;k&quot;</span>, label=<span class="string">f&quot;class <span class="subst">&#123;label&#125;</span> train&quot;</span>)</span><br><span class="line">    plot_x = (X_val[:, <span class="number">0</span>][Y_val == label],)</span><br><span class="line">    plot_y = (X_val[:, <span class="number">1</span>][Y_val == label],)</span><br><span class="line">    plt.scatter(plot_x, plot_y, c=color, marker=<span class="string">&quot;^&quot;</span>, ec=<span class="string">&quot;k&quot;</span>, label=<span class="string">f&quot;class <span class="subst">&#123;label&#125;</span> validation&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/./../../images/%E9%A1%B9%E7%9B%AE%E5%9B%BE/%E9%87%8F%E5%AD%90%E7%B4%AB%E8%96%87%E8%8A%B1/Figure_1.png"></p>
<h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pennylane as qml</span><br><span class="line">from pennylane <span class="keyword">import</span> numpy as np</span><br><span class="line">from pennylane.optimize <span class="keyword">import</span> NesterovMomentumOptimizer</span><br><span class="line">from numpy <span class="keyword">import</span> arcsin</span><br><span class="line"></span><br><span class="line">dev = qml.<span class="built_in">device</span>(<span class="string">&#x27;lightning.qubit&#x27;</span>, wires=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def <span class="built_in">get_angles</span>(x):</span><br><span class="line">    beta0 = <span class="number">2</span> * np.<span class="built_in">arcsin</span>(np.<span class="built_in">sqrt</span>(x[<span class="number">1</span>] ** <span class="number">2</span>) / np.<span class="built_in">sqrt</span>(x[<span class="number">0</span>] ** <span class="number">2</span> + x[<span class="number">1</span>] ** <span class="number">2</span> + <span class="number">1e-12</span>))</span><br><span class="line">    beta1 = <span class="number">2</span> * np.<span class="built_in">arcsin</span>(np.<span class="built_in">sqrt</span>(x[<span class="number">3</span>] ** <span class="number">2</span>) / np.<span class="built_in">sqrt</span>(x[<span class="number">2</span>] ** <span class="number">2</span> + x[<span class="number">3</span>] ** <span class="number">2</span> + <span class="number">1e-12</span>))</span><br><span class="line">    beta2 = <span class="number">2</span> * np.<span class="built_in">arcsin</span>(np.linalg.<span class="built_in">norm</span>(x[<span class="number">2</span>:]) / np.linalg.<span class="built_in">norm</span>(x))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">array</span>([beta2, -beta1 / <span class="number">2</span>, beta1 / <span class="number">2</span>, -beta0 / <span class="number">2</span>, beta0 / <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def <span class="built_in">state_preparation</span>(a):</span><br><span class="line">    qml.<span class="built_in">RY</span>(a[<span class="number">0</span>], wires=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    qml.<span class="built_in">CNOT</span>(wires=[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">    qml.<span class="built_in">RY</span>(a[<span class="number">1</span>], wires=<span class="number">1</span>)</span><br><span class="line">    qml.<span class="built_in">CNOT</span>(wires=[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">    qml.<span class="built_in">RY</span>(a[<span class="number">2</span>], wires=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    qml.<span class="built_in">PauliX</span>(wires=<span class="number">0</span>)</span><br><span class="line">    qml.<span class="built_in">CNOT</span>(wires=[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">    qml.<span class="built_in">RY</span>(a[<span class="number">3</span>], wires=<span class="number">1</span>)</span><br><span class="line">    qml.<span class="built_in">CNOT</span>(wires=[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">    qml.<span class="built_in">RY</span>(a[<span class="number">4</span>], wires=<span class="number">1</span>)</span><br><span class="line">    qml.<span class="built_in">PauliX</span>(wires=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = np.<span class="built_in">array</span>([<span class="number">0.53896774</span>, <span class="number">0.79503606</span>, <span class="number">0.27826503</span>, <span class="number">0.0</span>], requires_grad=False)</span><br><span class="line">ang = <span class="built_in">get_angles</span>(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@qml.<span class="built_in">qnode</span>(dev)</span><br><span class="line">def <span class="built_in">test</span>(angles):</span><br><span class="line">    <span class="built_in">state_preparation</span>(angles)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> qml.<span class="built_in">state</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">state = <span class="built_in">test</span>(ang)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x               : &quot;</span>, np.<span class="built_in">round</span>(x, <span class="number">6</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;angles          : &quot;</span>, np.<span class="built_in">round</span>(ang, <span class="number">6</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;amplitude vector: &quot;</span>, np.<span class="built_in">round</span>(np.<span class="built_in">real</span>(state), <span class="number">6</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;该方法计算了正确的角度以及准备所需要的态&quot;</span>)</span><br><span class="line"></span><br><span class="line">def <span class="built_in">square_loss</span>(labels, predictions):</span><br><span class="line">    # We use a call to qml.math.stack to allow subtracting the arrays directly</span><br><span class="line">    <span class="keyword">return</span> np.<span class="built_in">mean</span>((labels - qml.math.<span class="built_in">stack</span>(predictions)) ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def <span class="built_in">accuracy</span>(labels, predictions):</span><br><span class="line">    acc = <span class="built_in">sum</span>(<span class="built_in">abs</span>(l - p) &lt; <span class="number">1e-5</span> <span class="keyword">for</span> l, p in <span class="built_in">zip</span>(labels, predictions))</span><br><span class="line">    acc = acc / <span class="built_in">len</span>(labels)</span><br><span class="line">    <span class="keyword">return</span> acc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def <span class="built_in">layer</span>(layer_weights):</span><br><span class="line">    <span class="keyword">for</span> wire in <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        qml.<span class="built_in">Rot</span>(*layer_weights[wire], wires=wire)</span><br><span class="line">    qml.<span class="built_in">CNOT</span>(wires=[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def <span class="built_in">cost</span>(weights, bias, X, Y):</span><br><span class="line">    # Transpose the batch of input data in order to make the indexing</span><br><span class="line">    <span class="meta"># in state_preparation work</span></span><br><span class="line">    predictions = <span class="built_in">variational_classifier</span>(weights, bias, X.T)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">square_loss</span>(Y, predictions)</span><br><span class="line"></span><br><span class="line">@qml.<span class="built_in">qnode</span>(dev)</span><br><span class="line">def <span class="built_in">circuit</span>(weights, x):</span><br><span class="line">    <span class="built_in">state_preparation</span>(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> layer_weights in weights:</span><br><span class="line">        <span class="built_in">layer</span>(layer_weights)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> qml.<span class="built_in">expval</span>(qml.<span class="built_in">PauliZ</span>(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def <span class="built_in">variational_classifier</span>(weights, bias, x):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">circuit</span>(weights, x) + bias</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = np.<span class="built_in">loadtxt</span>(<span class="string">&quot;iris_classes1and2_scaled.txt&quot;</span>)</span><br><span class="line">X = data[:, <span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;First X sample (original)  : &#123;X[0]&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta"># pad the vectors to size 2^2=4 with constant values</span></span><br><span class="line">padding = np.<span class="built_in">ones</span>((<span class="built_in">len</span>(X), <span class="number">2</span>)) * <span class="number">0.1</span></span><br><span class="line">X_pad = np.c_[X, padding]</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;First X sample (padded)    : &#123;X_pad[0]&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta"># normalize each input</span></span><br><span class="line">normalization = np.<span class="built_in">sqrt</span>(np.<span class="built_in">sum</span>(X_pad**<span class="number">2</span>, <span class="number">-1</span>))</span><br><span class="line">X_norm = (X_pad.T / normalization).T</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;First X sample (normalized): &#123;X_norm[0]&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta"># the angles for state preparation are the features</span></span><br><span class="line">features = np.<span class="built_in">array</span>([<span class="built_in">get_angles</span>(x) <span class="keyword">for</span> x in X_norm], requires_grad=False)</span><br><span class="line"><span class="built_in">print</span>(f<span class="string">&quot;First features sample      : &#123;features[0]&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line">Y = data[:, <span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">plt.<span class="built_in">figure</span>()</span><br><span class="line">plt.<span class="built_in">scatter</span>(X[:, <span class="number">0</span>][Y == <span class="number">1</span>], X[:, <span class="number">1</span>][Y == <span class="number">1</span>], c=<span class="string">&quot;b&quot;</span>, marker=<span class="string">&quot;o&quot;</span>, ec=<span class="string">&quot;k&quot;</span>)</span><br><span class="line">plt.<span class="built_in">scatter</span>(X[:, <span class="number">0</span>][Y == <span class="number">-1</span>], X[:, <span class="number">1</span>][Y == <span class="number">-1</span>], c=<span class="string">&quot;r&quot;</span>, marker=<span class="string">&quot;o&quot;</span>, ec=<span class="string">&quot;k&quot;</span>)</span><br><span class="line">plt.<span class="built_in">title</span>(<span class="string">&quot;Original data&quot;</span>)</span><br><span class="line">plt.<span class="built_in">show</span>()</span><br><span class="line"></span><br><span class="line">plt.<span class="built_in">figure</span>()</span><br><span class="line">dim1 = <span class="number">0</span></span><br><span class="line">dim2 = <span class="number">1</span></span><br><span class="line">plt.<span class="built_in">scatter</span>(X_norm[:, dim1][Y == <span class="number">1</span>], X_norm[:, dim2][Y == <span class="number">1</span>], c=<span class="string">&quot;b&quot;</span>, marker=<span class="string">&quot;o&quot;</span>, ec=<span class="string">&quot;k&quot;</span>)</span><br><span class="line">plt.<span class="built_in">scatter</span>(X_norm[:, dim1][Y == <span class="number">-1</span>], X_norm[:, dim2][Y == <span class="number">-1</span>], c=<span class="string">&quot;r&quot;</span>, marker=<span class="string">&quot;o&quot;</span>, ec=<span class="string">&quot;k&quot;</span>)</span><br><span class="line">plt.<span class="built_in">title</span>(f<span class="string">&quot;Padded and normalised data (dims &#123;dim1&#125; and &#123;dim2&#125;)&quot;</span>)</span><br><span class="line">plt.<span class="built_in">show</span>()</span><br><span class="line"></span><br><span class="line">plt.<span class="built_in">figure</span>()</span><br><span class="line">dim1 = <span class="number">0</span></span><br><span class="line">dim2 = <span class="number">3</span></span><br><span class="line">plt.<span class="built_in">scatter</span>(features[:, dim1][Y == <span class="number">1</span>], features[:, dim2][Y == <span class="number">1</span>], c=<span class="string">&quot;b&quot;</span>, marker=<span class="string">&quot;o&quot;</span>, ec=<span class="string">&quot;k&quot;</span>)</span><br><span class="line">plt.<span class="built_in">scatter</span>(features[:, dim1][Y == <span class="number">-1</span>], features[:, dim2][Y == <span class="number">-1</span>], c=<span class="string">&quot;r&quot;</span>, marker=<span class="string">&quot;o&quot;</span>, ec=<span class="string">&quot;k&quot;</span>)</span><br><span class="line">plt.<span class="built_in">title</span>(f<span class="string">&quot;Feature vectors (dims &#123;dim1&#125; and &#123;dim2&#125;)&quot;</span>)</span><br><span class="line">plt.<span class="built_in">show</span>()</span><br><span class="line"></span><br><span class="line">np.random.<span class="built_in">seed</span>(<span class="number">0</span>)</span><br><span class="line">num_data = <span class="built_in">len</span>(Y)</span><br><span class="line">num_train = <span class="built_in">int</span>(<span class="number">0.75</span> * num_data)</span><br><span class="line">index = np.random.<span class="built_in">permutation</span>(<span class="built_in">range</span>(num_data))</span><br><span class="line">feats_train = features[index[:num_train]]</span><br><span class="line">Y_train = Y[index[:num_train]]</span><br><span class="line">feats_val = features[index[num_train:]]</span><br><span class="line">Y_val = Y[index[num_train:]]</span><br><span class="line"></span><br><span class="line"># We need these later <span class="keyword">for</span> plotting</span><br><span class="line">X_train = X[index[:num_train]]</span><br><span class="line">X_val = X[index[num_train:]]</span><br><span class="line"></span><br><span class="line">num_qubits = <span class="number">2</span></span><br><span class="line">num_layers = <span class="number">6</span></span><br><span class="line"></span><br><span class="line">weights_init = <span class="number">0.01</span> * np.random.<span class="built_in">randn</span>(num_layers, num_qubits, <span class="number">3</span>, requires_grad=True)</span><br><span class="line">bias_init = np.<span class="built_in">array</span>(<span class="number">0.0</span>, requires_grad=True)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">opt = <span class="built_in">NesterovMomentumOptimizer</span>(<span class="number">0.01</span>)</span><br><span class="line">batch_size = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="meta"># train the variational classifier</span></span><br><span class="line">weights = weights_init</span><br><span class="line">bias = bias_init</span><br><span class="line"><span class="keyword">for</span> it in <span class="built_in">range</span>(<span class="number">60</span>):</span><br><span class="line">    # Update the weights by one optimizer step</span><br><span class="line">    batch_index = np.random.<span class="built_in">randint</span>(<span class="number">0</span>, num_train, (batch_size,))</span><br><span class="line">    feats_train_batch = feats_train[batch_index]</span><br><span class="line">    Y_train_batch = Y_train[batch_index]</span><br><span class="line">    weights, bias, _, _ = opt.<span class="built_in">step</span>(cost, weights, bias, feats_train_batch, Y_train_batch)</span><br><span class="line"></span><br><span class="line">    # 在赋值权重后才可以加入可视化量子电路</span><br><span class="line">    <span class="keyword">if</span> it == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(f<span class="string">&quot;Iteration &#123;it + 1&#125;: Quantum Circuit Visualization:&quot;</span>)</span><br><span class="line">        fig = qml.<span class="built_in">draw_mpl</span>(circuit)(weights, ang)</span><br><span class="line">        plt.<span class="built_in">show</span>()</span><br><span class="line"></span><br><span class="line">    # Compute predictions on train <span class="keyword">and</span> validation set</span><br><span class="line">    predictions_train = np.<span class="built_in">sign</span>(<span class="built_in">variational_classifier</span>(weights, bias, feats_train.T))</span><br><span class="line">    predictions_val = np.<span class="built_in">sign</span>(<span class="built_in">variational_classifier</span>(weights, bias, feats_val.T))</span><br><span class="line"></span><br><span class="line">    # Compute accuracy on train <span class="keyword">and</span> validation set</span><br><span class="line">    acc_train = <span class="built_in">accuracy</span>(Y_train, predictions_train)</span><br><span class="line">    acc_val = <span class="built_in">accuracy</span>(Y_val, predictions_val)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (it + <span class="number">1</span>) % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">        _cost = <span class="built_in">cost</span>(weights, bias, features, Y)</span><br><span class="line">        <span class="built_in">print</span>(</span><br><span class="line">            f<span class="string">&quot;Iter: &#123;it + 1:5d&#125; | Cost: &#123;_cost:0.7f&#125; | &quot;</span></span><br><span class="line">            f<span class="string">&quot;Acc train: &#123;acc_train:0.7f&#125; | Acc validation: &#123;acc_val:0.7f&#125;&quot;</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">plt.<span class="built_in">figure</span>()</span><br><span class="line">cm = plt.cm.RdBu</span><br><span class="line"></span><br><span class="line"><span class="meta"># make data for decision regions</span></span><br><span class="line">xx, yy = np.<span class="built_in">meshgrid</span>(np.<span class="built_in">linspace</span>(<span class="number">0.0</span>, <span class="number">1.5</span>, <span class="number">30</span>), np.<span class="built_in">linspace</span>(<span class="number">0.0</span>, <span class="number">1.5</span>, <span class="number">30</span>))</span><br><span class="line">X_grid = [np.<span class="built_in">array</span>([x, y]) <span class="keyword">for</span> x, y in <span class="built_in">zip</span>(xx.<span class="built_in">flatten</span>(), yy.<span class="built_in">flatten</span>())]</span><br><span class="line"></span><br><span class="line"><span class="meta"># preprocess grid points like data inputs above</span></span><br><span class="line">padding = <span class="number">0.1</span> * np.<span class="built_in">ones</span>((<span class="built_in">len</span>(X_grid), <span class="number">2</span>))</span><br><span class="line">X_grid = np.c_[X_grid, padding]  <span class="meta"># pad each input</span></span><br><span class="line">normalization = np.<span class="built_in">sqrt</span>(np.<span class="built_in">sum</span>(X_grid**<span class="number">2</span>, <span class="number">-1</span>))</span><br><span class="line">X_grid = (X_grid.T / normalization).T  <span class="meta"># normalize each input</span></span><br><span class="line">features_grid = np.<span class="built_in">array</span>([<span class="built_in">get_angles</span>(x) <span class="keyword">for</span> x in X_grid])  <span class="meta"># angles are new features</span></span><br><span class="line">predictions_grid = <span class="built_in">variational_classifier</span>(weights, bias, features_grid.T)</span><br><span class="line">Z = np.<span class="built_in">reshape</span>(predictions_grid, xx.shape)</span><br><span class="line"></span><br><span class="line"><span class="meta"># plot decision regions</span></span><br><span class="line">levels = np.<span class="built_in">arange</span>(<span class="number">-1</span>, <span class="number">1.1</span>, <span class="number">0.1</span>)</span><br><span class="line">cnt = plt.<span class="built_in">contourf</span>(xx, yy, Z, levels=levels, cmap=cm, alpha=<span class="number">0.8</span>, extend=<span class="string">&quot;both&quot;</span>)</span><br><span class="line">plt.<span class="built_in">contour</span>(xx, yy, Z, levels=[<span class="number">0.0</span>], colors=(<span class="string">&quot;black&quot;</span>,), linestyles=(<span class="string">&quot;--&quot;</span>,), linewidths=(<span class="number">0.8</span>,))</span><br><span class="line">plt.<span class="built_in">colorbar</span>(cnt, ticks=[<span class="number">-1</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta"># plot data</span></span><br><span class="line"><span class="keyword">for</span> color, label in <span class="built_in">zip</span>([<span class="string">&quot;b&quot;</span>, <span class="string">&quot;r&quot;</span>], [<span class="number">1</span>, <span class="number">-1</span>]):</span><br><span class="line">    plot_x = X_train[:, <span class="number">0</span>][Y_train == label]</span><br><span class="line">    plot_y = X_train[:, <span class="number">1</span>][Y_train == label]</span><br><span class="line">    plt.<span class="built_in">scatter</span>(plot_x, plot_y, c=color, marker=<span class="string">&quot;o&quot;</span>, ec=<span class="string">&quot;k&quot;</span>, label=f<span class="string">&quot;class &#123;label&#125; train&quot;</span>)</span><br><span class="line">    plot_x = (X_val[:, <span class="number">0</span>][Y_val == label],)</span><br><span class="line">    plot_y = (X_val[:, <span class="number">1</span>][Y_val == label],)</span><br><span class="line">    plt.<span class="built_in">scatter</span>(plot_x, plot_y, c=color, marker=<span class="string">&quot;^&quot;</span>, ec=<span class="string">&quot;k&quot;</span>, label=f<span class="string">&quot;class &#123;label&#125; validation&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.<span class="built_in">legend</span>()</span><br><span class="line">plt.<span class="built_in">show</span>()</span><br></pre></td></tr></table></figure>

<h2 id="完整流程图"><a href="#完整流程图" class="headerlink" title="完整流程图"></a>完整流程图</h2><h2 id="知识拓展"><a href="#知识拓展" class="headerlink" title="知识拓展"></a>知识拓展</h2></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">陈智涛</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2024/11/30/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97%E9%A1%B9%E7%9B%AE/%E9%87%8F%E5%AD%90%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%88%86%E7%B1%BB/">http://example.com/2024/11/30/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97%E9%A1%B9%E7%9B%AE/%E9%87%8F%E5%AD%90%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%88%86%E7%B1%BB/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">ZTCodeGarden</a>！</span></div></div><div class="tag_share"><div class="post-share"><div class="social-share" data-image="/img/01.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related  no-desc" href="/2024/12/01/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/" title="神经网络架构"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">神经网络架构</div></div></div></a><a class="pagination-related" href="/2024/11/30/%E5%8A%9B%E6%89%A3/%E8%B4%AA%E5%BF%83%E7%AF%87/Leecode860%E6%9F%A0%E6%AA%AC%E6%B0%B4%E6%89%BE%E9%9B%B6/" title="Leecode860柠檬水找零"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Leecode860柠檬水找零</div></div><div class="info-2"><div class="info-item-1">问题 思路  这道题非常简单，我们目标是实现找零，那么我必然要保证手上时刻都有最多的最小零钱，因为最小零钱可以找散任意零钱。 可以分一下三种情况讨论 1.如果是5元零钱，我们直接搜集起来 2.如果是10元零钱，我们就用5元零钱找散 3.如果是20元零钱，我们优先使用10元和5元来找散，否则使用3个5元来找散 完整代码123456789101112131415161718192021222324252627282930313233343536373839class Solution &#123;public:    bool lemonadeChange(vector&lt;int&gt;&amp; bills) &#123;        //统计5元，10元        //5元直接收，10元必须有5元找零，20元必须有10元或5元才能找零        int fiveBill = 0;        int tenBill = 0;        for(int i = 0; i &lt; bills.size(); i++)        &#123;        ...</div></div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/01.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">陈智涛</div><div class="author-info-description">纵使前路茫茫，莫回头，随心荡人间</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">16</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A1%B9%E7%9B%AE%E8%AF%B4%E6%98%8E"><span class="toc-number">1.</span> <span class="toc-text">项目说明</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%9C%E7%94%A8"><span class="toc-number">1.1.</span> <span class="toc-text">作用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE"><span class="toc-number">2.</span> <span class="toc-text">处理数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%90%E4%B8%AA%E4%BB%A3%E7%A0%81%E5%89%96%E6%9E%90"><span class="toc-number">2.1.</span> <span class="toc-text">逐个代码剖析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E9%A1%B9%E7%9B%AE%E6%89%80%E9%9C%80%E5%A4%B4%E6%96%87%E4%BB%B6"><span class="toc-number">2.1.1.</span> <span class="toc-text">1. 项目所需头文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E6%89%80%E4%BD%BF%E7%94%A8%E7%9A%84%E9%87%8F%E5%AD%90%E8%AE%BE%E5%A4%87"><span class="toc-number">2.1.2.</span> <span class="toc-text">2.所使用的量子设备</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E8%AE%A1%E7%AE%97%E8%BE%93%E5%85%A5%E6%95%B0%E7%BB%84%E7%9A%84%E8%A7%92%E5%BA%A6%E5%80%BC"><span class="toc-number">2.1.3.</span> <span class="toc-text">3.计算输入数组的角度值</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E9%87%8F%E5%AD%90%E7%BA%BF%E8%B7%AF%E5%87%86%E5%A4%87"><span class="toc-number">2.1.4.</span> <span class="toc-text">4.量子线路准备</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-%E6%B5%8B%E8%AF%95%E8%AE%BE%E8%AE%A1%E7%9A%84%E9%87%8F%E5%AD%90%E7%BA%BF%E8%B7%AF%E6%98%AF%E5%90%A6%E6%9C%89%E6%95%88"><span class="toc-number">2.1.5.</span> <span class="toc-text">5.测试设计的量子线路是否有效</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-%E4%B8%80%E4%BA%9B%E6%B5%8B%E8%AF%95%E5%87%BD%E6%95%B0"><span class="toc-number">2.1.6.</span> <span class="toc-text">6.一些测试函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-%E9%87%8D%E6%9E%84%E9%87%8F%E5%AD%90%E5%B1%82"><span class="toc-number">2.1.7.</span> <span class="toc-text">7.重构量子层</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E9%87%8A%EF%BC%9A"><span class="toc-number">2.2.</span> <span class="toc-text">解释：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#8-%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E5%92%8C%E5%8F%98%E5%88%86%E9%87%8F%E5%AD%90%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-number">2.2.1.</span> <span class="toc-text">8.全连接层和变分量子分类器</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E9%87%8A%EF%BC%9A-1"><span class="toc-number">2.3.</span> <span class="toc-text">解释：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#9-%E6%95%B0%E6%8D%AE"><span class="toc-number">2.3.1.</span> <span class="toc-text">9.数据</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E6%95%B0%E6%8D%AE%E6%89%A9%E7%BB%B4%E5%BA%A6%E6%9D%A5%E5%8C%B9%E9%85%8D%E7%9B%B8%E5%BA%94%E7%9A%84%E6%80%81"><span class="toc-number">2.3.1.1.</span> <span class="toc-text">（1）数据扩维度来匹配相应的态</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E9%87%8A%EF%BC%9A-2"><span class="toc-number">2.4.</span> <span class="toc-text">解释：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%EF%BC%882%EF%BC%89%E5%BD%92%E4%B8%80%E5%8C%96%E5%A4%84%E7%90%86"><span class="toc-number">2.4.0.1.</span> <span class="toc-text">（2）归一化处理</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%90%8E%E5%8F%AF%E8%A7%86%E5%8C%96%E5%A4%84%E7%90%86"><span class="toc-number">2.4.1.</span> <span class="toc-text">10.数据处理后可视化处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11-%E6%B3%9B%E5%8C%96"><span class="toc-number">2.4.2.</span> <span class="toc-text">11.泛化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-%E4%BC%98%E5%8C%96"><span class="toc-number">2.4.3.</span> <span class="toc-text">12.优化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13-%E7%BB%98%E5%88%B6-Iris-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%89%8D%E4%B8%A4%E4%B8%AA%E7%BB%B4%E7%9A%84%E5%8F%98%E5%88%86%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E8%BF%9E%E7%BB%AD%E8%BE%93%E5%87%BA"><span class="toc-number">2.4.4.</span> <span class="toc-text">13.绘制 Iris 数据集前两个维的变分分类器的连续输出</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81"><span class="toc-number">3.</span> <span class="toc-text">完整代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E6%B5%81%E7%A8%8B%E5%9B%BE"><span class="toc-number">4.</span> <span class="toc-text">完整流程图</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E6%8B%93%E5%B1%95"><span class="toc-number">5.</span> <span class="toc-text">知识拓展</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><div class="content"><a class="title" href="/2024/12/04/%E5%8A%9B%E6%89%A3/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%AF%87/509-%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0/" title="509.斐波那契数">509.斐波那契数</a><time datetime="2024-12-04T01:06:32.000Z" title="发表于 2024-12-04 09:06:32">2024-12-04</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/2024/12/03/%E9%87%8F%E5%AD%90%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/World/" title="World">World</a><time datetime="2024-12-03T12:20:53.000Z" title="发表于 2024-12-03 20:20:53">2024-12-03</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/2024/12/03/%E9%87%8F%E5%AD%90%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Qiski%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%EF%BC%88%E4%B8%80%EF%BC%89/" title="Qiski使用指南（一）">Qiski使用指南（一）</a><time datetime="2024-12-03T03:20:25.000Z" title="发表于 2024-12-03 11:20:25">2024-12-03</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/2024/12/03/%E5%8A%9B%E6%89%A3/%E8%B4%AA%E5%BF%83%E7%AF%87/LECODE738%E5%8D%95%E8%B0%83%E9%80%92%E5%A2%9E%E7%9A%84%E6%95%B0%E5%AD%97/" title="LECODE738单调递增的数字">LECODE738单调递增的数字</a><time datetime="2024-12-03T02:02:06.000Z" title="发表于 2024-12-03 10:02:06">2024-12-03</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/2024/12/02/%E5%8A%9B%E6%89%A3/%E8%B4%AA%E5%BF%83%E7%AF%87/LEECODE56%E5%90%88%E5%B9%B6%E5%8C%BA%E9%97%B4/" title="LEECODE56合并区间">LEECODE56合并区间</a><time datetime="2024-12-02T14:27:53.000Z" title="发表于 2024-12-02 22:27:53">2024-12-02</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By 陈智涛</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>